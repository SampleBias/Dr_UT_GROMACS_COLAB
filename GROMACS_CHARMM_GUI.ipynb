{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4253443e",
   "metadata": {},
   "source": [
    "#### Documentation\n",
    "**Before using this notebook, please click the *cells hidden* button below to show the documentation.**\n",
    "##### License\n",
    "> This notebook as a work of software is licensed under the terms of the [AGPL-3.0](https://opensource.org/licenses/AGPL-3.0) or later.\n",
    "##### About this software\n",
    "> This notebook processes a **[CHARMM-GUI](https://www.charmm-gui.org/) system archive** (`.tgz`), producing a **GROMACS-ready folder for production runs**.\n",
    ">\n",
    "> A protein system prepared with the CHARMM-GUI **Solution Builder** or **Membrane Builder** must be provided.\n",
    ">\n",
    "> <font color=\"maroon\">Warning: In CHARMM-GUI, the option to generate GROMACS compatible outputs **must** be enabled.</font>\n",
    ">\n",
    "> The recommended **minimisation** and **equilibration** simulations are then run with **GROMACS**, which automatically utilises the GPU if one is allocated. The equilibrated system is saved for a later production simulation.\n",
    "##### Installation\n",
    "> The installation notebook, [`Build_to_Google_Drive.ipynb`](https://colab.research.google.com/github/bioinfkaustin/gromacs-on-colab/blob/main/Build_to_Google_Drive.ipynb), must be run before using this notebook.\n",
    "##### Piecewise preparation of protein-ligand complexes\n",
    "> *Optionally*, a docked ligand conformation prepared with the CHARMM-GUI **Ligand Reader** may be provided, in which case the two separate structures and topologies will be **merged into a protein-ligand complex**.\n",
    ">\n",
    "> <font color=\"maroon\">Warning: The protein `.tgz` **must** be the **protein docked against**, and the ligand `.tgz` **must** be the **docking output**.</font>\n",
    "> To merge **multiple** cooperatively bound ligands, **multiple paths to archive files** are separated by the `|` keyword.\n",
    "> *e.g.*\n",
    "> ```\n",
    "> ligand_archives = \"{GoogleDrive}/diazepam.tgz | {GoogleDrive}/GABA.tgz\"\n",
    "> ```\n",
    "> The above example merges docked conformations of diazepam and GABA into a protein system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c40ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from functools import partial\n",
    "\n",
    "#@markdown Provide the location of the `.tgz` from **Solution Builder** or **Membrane Builder**.\n",
    "protein_archive = \"{GoogleDrive}/CHARMM-GUI/7FBF_FABPH.tgz\" #@param {type: \"string\"}\n",
    "\n",
    "#@markdown Specify a new folder in which to save the equilibrated output -- the production simulation can then be run in this folder.\n",
    "output_folder = \"{GoogleDrive}/GROMACS/7FBF_FABPH_vs_octanoic_acid\" #@param {type: \"string\"}\n",
    "\n",
    "#@markdown If applicable, please see also the advanced settings below. **After filling in this form, run the notebook by clicking *Runtime -> Run all* in the toolbar.**\n",
    "\n",
    "#@markdown \\\n",
    "#@markdown **Merging docked ligands into the system**\n",
    "#@markdown Optionally, docked ligand conformations may be added to the system, provided as `.tgz` archives from **Ligand Reader**.\n",
    "ligand_archives = \"{GoogleDrive}/CHARMM-GUI/7FBF_octanoic_acid.tgz\" #@param {type: \"string\"}\n",
    "\n",
    "#@markdown \\\n",
    "#@markdown **Expert settings**\n",
    "#@markdown Optionally, equilibrate the system for double the suggested time.\n",
    "double_equilibration_length = False #@param {type: \"boolean\"}\n",
    "\n",
    "#@markdown Optionally, remove correction maps (CMAP terms). This will **[decrease the accuracy](https://pubs.acs.org/doi/10.1021/ct900549r)** of the production simulation but substantially improve performance on high-end GPUs (e.g. A100).\n",
    "remove_cmap_terms = False #@param {type: \"boolean\"}\n",
    "\n",
    "# Google Drive\n",
    "if not os.path.isdir(\"/content/drive/MyDrive\"):\n",
    "  from google.colab import drive\n",
    "  drive.mount(\"/content/drive\")\n",
    "if not os.path.isdir(\"/content/drive/MyDrive\"):\n",
    "  raise RuntimeError(\"Error: could not connect to Google Drive\")\n",
    "\n",
    "# Methods for parsing and validation\n",
    "def _multiple(s):\n",
    "  return list(filter(None, s.split(\"|\")))\n",
    "def _path(s, exists=False, exts=None):\n",
    "  if \"{GoogleDrive}\" in s and not s.startswith(\"{GoogleDrive}\"): raise ValueError(f\"Error: {{GoogleDrive}} is a path prefix, but appears later: {s}\")\n",
    "  s = s.format(GoogleDrive=\"/content/drive/MyDrive\")\n",
    "  if exists and not os.path.isfile(s): raise FileNotFoundError(f\"Error: file not found: {s}\")\n",
    "  if exts and not any(s.endswith(ext) for ext in exts): raise ValueError(f\"Error: expecting file extension like {', '.join(exts)}, but got: {s}\")\n",
    "  return os.path.abspath(s)\n",
    "_extra_spaces = re.compile(r\"(^ +|(?<=\\|) +| +(?=\\|)| +$)\")\n",
    "def parse(s, multiple=False, mandatory=False, path=False, exists=False, exts=None):\n",
    "  s = _extra_spaces.sub(\"\", s)\n",
    "  if multiple:\n",
    "    s = _multiple(s)\n",
    "  if mandatory and (multiple and not any(v for v in s) or not multiple and not s):\n",
    "    raise ValueError(\"Error: mandatory setting without value\")\n",
    "  if path:\n",
    "    _path_preset = partial(_path, exists=exists, exts=exts)\n",
    "    if multiple: s = [_path_preset(v) for v in s]\n",
    "    else: s = _path_preset(s)\n",
    "  return s\n",
    "\n",
    "archive_exts = [\".tgz\", \".tar.gz\"]\n",
    "protein_archive = parse(protein_archive, mandatory=True, path=True, exists=True, exts=archive_exts)\n",
    "output_folder = parse(output_folder, mandatory=True, path=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "if os.path.isfile(output_folder + \"/conf.gro\"):\n",
    "  raise RuntimeError(f\"Error: expecting empty folder, but found existing output: {output_folder}\")\n",
    "\n",
    "ligand_archives = parse(ligand_archives, multiple=True, path=True, exists=True, exts=archive_exts)\n",
    "ligands_bash = \"|\".join(ligand_archives)\n",
    "\n",
    "do_double_eq_bash = \"true\" if double_equilibration_length else \"false\"\n",
    "remove_cmaps_bash = \"true\" if remove_cmap_terms else \"false\"\n",
    "\n",
    "if \"START\" not in os.environ or not os.environ[\"START\"]:\n",
    "  %env START={os.getcwd()}\n",
    "else:\n",
    "  %cd {os.environ[\"START\"]}\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(\"scratch\")\n",
    "except FileNotFoundError:\n",
    "  pass\n",
    "os.makedirs(\"scratch\")\n",
    "%cd \"scratch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339af64b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$protein_archive\"\n",
    "protein_archive=\"$1\"\n",
    "\n",
    "#@markdown Extract the system from the protein archive. This should come from either **Solution Builder** or **Membrane Builder**.\n",
    "if [[ -d \"protein\" ]]; then\n",
    "  exit 0 # already extracted protein\n",
    "fi\n",
    "if [[ ! -s \"${protein_archive}\" ]]; then\n",
    "  echo \"Error: file not found: ${protein_archive}\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "tar -xzf \"${protein_archive}\"\n",
    "if ! compgen -G \"charmm-gui-*/\" > /dev/null; then\n",
    "  echo \"Error: not in CHARMM-GUI archive format: ${protein_archive}\" 1>&2\n",
    "  exit 1\n",
    "fi\n",
    "mv charmm-gui-*/ \"protein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d0eba",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$ligands_bash\"\n",
    "ligand_archives=\"$1\"\n",
    "\n",
    "#@markdown Extract the docked ligands from the ligand archives, if given. These files **must** come from putting the **docking output** into **Ligand Reader**.\n",
    "if compgen -G \"ligand_*/\" > /dev/null; then\n",
    "  exit 0 # already extracted ligand(s)\n",
    "fi\n",
    "i=1\n",
    "IFS=\"|\"\n",
    "for ligand_archive in $ligand_archives; do\n",
    "  if [[ ! -s \"${ligand_archive}\" ]]; then\n",
    "    echo \"Error: file not found: ${ligand_archive}\" >&2\n",
    "    exit 1\n",
    "  fi\n",
    "  tar -xzf \"${ligand_archive}\"\n",
    "  if ! compgen -G \"charmm-gui-*/\" > /dev/null; then\n",
    "    echo \"Error: not in CHARMM-GUI archive format: ${ligand_archive}\" 1>&2\n",
    "    exit 1\n",
    "  fi\n",
    "  mv charmm-gui-*/ \"ligand_${i}\"\n",
    "  i=$(($i + 1))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e9a70",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown In the following cells, applications are downloaded from a **persistent cache** in your Google Drive.\n",
    "#@markdown This cell sets up the cache folder.\n",
    "storage = \"/content/drive/MyDrive/gromacs-on-colab\"\n",
    "%env STORAGE={storage}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1066b3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#@markdown Install Miniconda environments for `cgenff_charmm2gmx.py` and **Biopython** / **Open Babel** from cache.\n",
    "if [[ -d \"${START}/miniconda3\" ]]; then\n",
    "  exit 0 # already installed\n",
    "fi\n",
    "miniconda3_vers=\"py310_23.5.2-0\" #@param {type: \"string\"}\n",
    "cache_miniconda3_installer=\"${STORAGE}/Miniconda3-${miniconda3_vers}-Linux-x86_64.sh.tar.gz\"\n",
    "if [[ -s \"${cache_miniconda3_installer}\" ]]; then\n",
    "  tar -xzf \"${cache_miniconda3_installer}\"\n",
    "else\n",
    "  echo \"Error: Miniconda installer not found\" >&2\n",
    "  echo \"(Have you installed Miniconda to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "bash \"Miniconda3-${miniconda3_vers}-Linux-x86_64.sh\" -b -p \"${START}/miniconda3\"\n",
    "rm \"Miniconda3-${miniconda3_vers}-Linux-x86_64.sh\"\n",
    "eval \"$(\"$START/miniconda3/bin/conda\" shell.bash hook)\"\n",
    "cache_miniconda3=\"${STORAGE}/Miniconda3-${miniconda3_vers}-Linux-x86_64_envs.tar.gz\"\n",
    "if [[ -s \"${cache_miniconda3}\" ]]; then\n",
    "  tar -xzf \"${cache_miniconda3}\" -C \"${START}/miniconda3\"\n",
    "else\n",
    "  echo \"Error: Miniconda environments not found\" >&2\n",
    "  echo \"(Have you installed Miniconda to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484063a6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#@markdown Install Miniconda environments for `cgenff_charmm2gmx.py` and **Biopython** / **Open Babel** from cache.\n",
    "if [[ -d \"${START}/miniconda3\" ]]; then\n",
    "  exit 0 # already installed\n",
    "fi\n",
    "miniconda3_vers=\"py310_23.5.2-0\" #@param {type: \"string\"}\n",
    "cache_miniconda3_installer=\"${STORAGE}/Miniconda3-${miniconda3_vers}-Linux-x86_64.sh.tar.gz\"\n",
    "if [[ -s \"${cache_miniconda3_installer}\" ]]; then\n",
    "  tar -xzf \"${cache_miniconda3_installer}\"\n",
    "else\n",
    "  echo \"Error: Miniconda installer not found\" >&2\n",
    "  echo \"(Have you installed Miniconda to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "bash \"Miniconda3-${miniconda3_vers}-Linux-x86_64.sh\" -b -p \"${START}/miniconda3\"\n",
    "rm \"Miniconda3-${miniconda3_vers}-Linux-x86_64.sh\"\n",
    "eval \"$(\"$START/miniconda3/bin/conda\" shell.bash hook)\"\n",
    "cache_miniconda3=\"${STORAGE}/Miniconda3-${miniconda3_vers}-Linux-x86_64_envs.tar.gz\"\n",
    "if [[ -s \"${cache_miniconda3}\" ]]; then\n",
    "  tar -xzf \"${cache_miniconda3}\" -C \"${START}/miniconda3\"\n",
    "else\n",
    "  echo \"Error: Miniconda environments not found\" >&2\n",
    "  echo \"(Have you installed Miniconda to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f904c8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#@markdown The CHARMM36 forcefield is downloaded from cache.\n",
    "if [[ -d \"${START}/charmm36.ff\" ]]; then\n",
    "  exit 0 # already installed\n",
    "fi\n",
    "charmm36_vers=\"jul2022\" #@param {type: \"string\"}\n",
    "cache_charmm36=\"${STORAGE}/charmm36-${charmm36_vers}.tar.gz\"\n",
    "if [[ -s \"${cache_charmm36}\" ]]; then\n",
    "  tar -xzf \"${cache_charmm36}\" -C \"${START}\"\n",
    "else\n",
    "  echo \"Error: CHARMM36 forcefield installation not found\" >&2\n",
    "  echo \"(Have you installed the CHARMM36 forcefield to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f780d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#@markdown The utility **`cgenff_charmm2gmx.py`** is installed from cache.\n",
    "if [[ -x \"$START/miniconda3/envs/charmm2gmx/bin/cgenff_charmm2gmx.py\" ]]; then\n",
    "  exit 0 # already installed\n",
    "fi\n",
    "charmm2gmx_vers=\"py3_nx2\" #@param {type: \"string\"}\n",
    "cache_charmm2gmx=\"$STORAGE/cgenff_charmm2gmx_${charmm2gmx_vers}.tar.gz\"\n",
    "if [[ -s \"${cache_charmm2gmx}\" ]]; then\n",
    "  tar -xzf \"${cache_charmm2gmx}\" -C \"${START}/miniconda3/envs/charmm2gmx/bin\"\n",
    "else\n",
    "  echo \"Error: charmm2gmx installation not found\" >&2\n",
    "  echo \"(Have you installed charmm2gmx to your Google Drive?)\" >&2\n",
    "  exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f89dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A class which allows for the parsing and limited editing of **GROMACS \".itp\" topology files**.\n",
    "from collections import namedtuple\n",
    "T = namedtuple(\"T\", [\"line\", \"comment\"])\n",
    "class Itp:\n",
    "  def __init__(self, filename):\n",
    "    self.blocks = [None]\n",
    "    self.data = [[]]\n",
    "    with open(filename) as f:\n",
    "      self.__parse(f)\n",
    "  def __parse(self, lines):\n",
    "    columns = re.compile(r\"\\b(?=[ \\t])\")\n",
    "    concat = None\n",
    "    for l in lines:\n",
    "      l = l.rstrip(\"\\n\")\n",
    "      l = l.replace(\"\\t\", \" \")\n",
    "      if l.endswith(\"\\\\\"):\n",
    "        if concat is None:\n",
    "          concat = l[:-1] + \" \"\n",
    "        else:\n",
    "          concat += l[:-1] + \" \"\n",
    "        continue\n",
    "      elif concat is not None:\n",
    "        l = concat + l\n",
    "        concat = None\n",
    "      try:\n",
    "        l, c = l.split(\";\")\n",
    "      except ValueError:\n",
    "        c = None\n",
    "      l_ = l.strip()\n",
    "      if l_.startswith(\"[\"):\n",
    "        self.blocks.append(T(line=l, comment=c))\n",
    "        self.data.append([])\n",
    "      elif l_ and not l_.startswith(\"#\"):\n",
    "        s = columns.split(l)\n",
    "        self.data[-1].append(T(line=s, comment=c))\n",
    "      else:\n",
    "        self.data[-1].append(T(line=l, comment=c))\n",
    "  def print(self, file=None):\n",
    "    for block, data in zip(self.blocks, self.data):\n",
    "      if block is not None:\n",
    "        print(self._str(block), file=file)\n",
    "      for t in data:\n",
    "        print(self._str(t), file=file)\n",
    "  def _str(self, t):\n",
    "    l = t.line if isinstance(t.line, str) else \"\".join(t.line)\n",
    "    if t.comment is not None:\n",
    "      l += \";\" + t.comment\n",
    "    return l\n",
    "  @classmethod\n",
    "  def only(cls, data):\n",
    "    return filter(lambda t: isinstance(t[0], list), data)\n",
    "\n",
    "  directive_order_hint = [None, \"defaults\", \"atomtypes\", \"bondtypes\", \"pairtypes\", \"angletypes\", \"dihedraltypes\", \"constrainttypes\", \"nonbond_params\"]\n",
    "  block_num_atom_cols = {\n",
    "    \"atoms\": 1, \"bonds\": 2, \"pairs\": 2,\n",
    "    \"pairs_nb\": 2, \"angles\": 3, \"dihedrals\": 4,\n",
    "    \"exclusions\": -1, \"constraints\": 2, \"settles\": 1,\n",
    "    \"virtual_sites1\": 2, \"virtual_sites2\": 3, \"virtual_sites3\": 4,\n",
    "    \"virtual_sites4\": 5, \"virtual_sitesn\": 1, \"position_restraints\": 1,\n",
    "    \"distance_restraints\": 2, \"dihedral_restraints\": 4, \"orientation_restraints\": 2,\n",
    "    \"angle_restraints\": 4, \"angle_restraints_z\": 2\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c78eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A function which modifies an Itp topology object `x`, changing the order of its atom definitions such that hydrogens immediately follow their bonded heavy atoms.\n",
    "from types import SimpleNamespace\n",
    "S = lambda: SimpleNamespace(atom_obj=dict(), atom_element=dict(), atom_bonded_atoms=dict())\n",
    "def interleave_H_in_topology(x):\n",
    "  element = re.compile(r\"(?<=[a-zA-Z])(?=[0-9])\")\n",
    "  cache = dict()\n",
    "  name = None\n",
    "  for block, data in zip(x.blocks, x.data):\n",
    "    if block is None: continue\n",
    "    block_line_ = block.line.replace(\" \", \"\")\n",
    "    if \"[moleculetype]\" in block_line_:\n",
    "      name = next(Itp.only(data)).line[0].strip()\n",
    "      cache[name] = S()\n",
    "    elif \"[atoms]\" in block_line_:\n",
    "      for t in Itp.only(data):\n",
    "        l, c = t\n",
    "        atom_id = int(l[0])\n",
    "        cache[name].atom_obj[atom_id] = t\n",
    "        cache[name].atom_element[atom_id] = element.split(l[4])[0].strip()\n",
    "    elif \"[bonds]\" in block_line_:\n",
    "      for l, c in Itp.only(data):\n",
    "        u, v = int(l[0]), int(l[1])\n",
    "        for u_, v_ in ((u, v), (v, u)):\n",
    "          try:\n",
    "            cache[name].atom_bonded_atoms[u_].append(v_)\n",
    "          except KeyError:\n",
    "            cache[name].atom_bonded_atoms[u_] = [v_]\n",
    "\n",
    "  name = None\n",
    "  new_data = dict()\n",
    "  for i, (block, data) in enumerate(zip(x.blocks, x.data)):\n",
    "    if block is None: continue\n",
    "    block_line_ = block.line.replace(\" \", \"\")\n",
    "    if \"[moleculetype]\" in block_line_:\n",
    "      name = next(Itp.only(data)).line[0].strip()\n",
    "    elif \"[atoms]\" in block_line_:\n",
    "      new_data[i] = list()\n",
    "      skip = list()\n",
    "      for t in data:\n",
    "        l, c = t\n",
    "        if isinstance(l, list):\n",
    "          atom_id = int(l[0])\n",
    "          if atom_id not in skip:\n",
    "            if cache[name].atom_element[atom_id] != \"H\":\n",
    "              new_data[i].append(t)\n",
    "              if atom_id in cache[name].atom_bonded_atoms:\n",
    "                for other_id in cache[name].atom_bonded_atoms[atom_id]:\n",
    "                  if cache[name].atom_element[other_id] == \"H\":\n",
    "                    new_data[i].append(cache[name].atom_obj[other_id])\n",
    "                    skip.append(other_id)\n",
    "            elif atom_id not in cache[name].atom_bonded_atoms:\n",
    "              new_data[i].append(t)\n",
    "        else:\n",
    "          new_data[i].append(t)\n",
    "  for key, value in new_data.items():\n",
    "    x.data[key] = value\n",
    "\n",
    "  name = None\n",
    "  new_id = None\n",
    "  atom_id_map = None\n",
    "  def str_like(number, template):\n",
    "    return f\"%{len(template)}d\" % (number,)\n",
    "  for block, data in zip(x.blocks, x.data):\n",
    "    if block is None: continue\n",
    "    block_line_ = block.line.replace(\" \", \"\")\n",
    "    if \"[moleculetype]\" in block_line_:\n",
    "      name = next(Itp.only(data)).line[0].strip()\n",
    "      new_id = 1\n",
    "      atom_id_map = dict()\n",
    "    elif \"[atoms]\" in block_line_:\n",
    "      for l, c in Itp.only(data):\n",
    "        atom_id = int(l[0])\n",
    "        l[0] = str_like(new_id, l[0])\n",
    "        atom_id_map[atom_id] = new_id\n",
    "        new_id += 1\n",
    "    else:\n",
    "      for key, num_cols in Itp.block_num_atom_cols.items():\n",
    "        if f\"[{key}]\" in block_line_:\n",
    "          for l, c in Itp.only(data):\n",
    "            if num_cols < 0:\n",
    "              num_cols = len(l)\n",
    "            for i in range(num_cols):\n",
    "              this_id = int(l[i])\n",
    "              l[i] = str_like(atom_id_map[this_id], l[i])\n",
    "          break\n",
    "  return atom_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5985c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A class which allows for the parsing and limited editing of **GROMACS \".gro\" coordinates files**.\n",
    "class Gro:\n",
    "  def __init__(self, filename):\n",
    "    self.title = None\n",
    "    self.info = list()\n",
    "    self.pos = list()\n",
    "    self.vel = None\n",
    "    self.width = None\n",
    "    self.box = None\n",
    "    self.box_explicit_diag = None\n",
    "    self.box_width = None\n",
    "    with open(filename) as f:\n",
    "      self.__parse(f)\n",
    "  def __parse(self, lines):\n",
    "    n = None\n",
    "    for i, l in enumerate(lines):\n",
    "      l = l.rstrip(\"\\n\")\n",
    "      if i == 0: self.title = l\n",
    "      elif i == 1: n = int(l)\n",
    "      elif 2 <= i < 2 + n:\n",
    "        s = l[:20]\n",
    "        d = l[20:].rstrip()\n",
    "        if i == 2:\n",
    "          num_dots = len([x for x in l if x == \".\"])\n",
    "          if num_dots == 3: pass\n",
    "          elif num_dots == 6: self.vel = list()\n",
    "          else: raise RuntimeError(f\"Error: expected 3 or 6 data columns, but got: {d}\")\n",
    "          if len(d) % num_dots != 0:\n",
    "            raise RuntimeError(f\"Error: expected consistent column width for {num_dots} columns, but got: {d}\")\n",
    "          self.width = len(d) // num_dots\n",
    "        info = (int(s[:5]), s[5:10].strip(), s[10:15].strip(), int(s[15:20]))\n",
    "        self.info.append(info)\n",
    "        pos = tuple(float(d[x:x+self.width]) for x in range(0, 3 * self.width, self.width))\n",
    "        self.pos.append(pos)\n",
    "        if self.vel is not None:\n",
    "          vel = tuple(float(d[x:x+self.width]) for x in range(3 * self.width, 6 * self.width, self.width))\n",
    "          self.vel.append(vel)\n",
    "      elif i == 2 + n:\n",
    "        l = l.rstrip()\n",
    "        num_dots = len([x for x in l if x == \".\"])\n",
    "        if num_dots == 3: self.box_explicit_diag = False\n",
    "        elif num_dots == 9: self.box_explicit_diag = True\n",
    "        else: raise RuntimeError(f\"Error: expected 3 or 9 box columns, but got: {l}\")\n",
    "        if len(l) % num_dots != 0:\n",
    "          raise RuntimeError(f\"Error: expected consistent column width for box vector, but got: {l}\")\n",
    "        self.box_width = len(l) // num_dots\n",
    "        self.box = tuple(float(l[x:x+self.box_width]) for x in range(0, len(l), self.box_width))\n",
    "      else:\n",
    "        raise RuntimeError(f\"Error: expected EOF, but got: {l}\")\n",
    "  def print(self, file=None):\n",
    "    print(self.title, file=file)\n",
    "    print(\"%5d\" % (len(self.info),), file=file)\n",
    "    w = self.width\n",
    "    p = w - 5\n",
    "    if self.vel is not None:\n",
    "      v = w - 4\n",
    "      fmt = \"%5d%-5s%5s%5d\" + f\"%{w}.{p}f\" * 3 + f\"%{w}.{v}f\" * 3\n",
    "      def fit(x):\n",
    "        return ((x - 1) % 99999) + 1\n",
    "      for info, pos, vel in zip(self.info, self.pos, self.vel):\n",
    "        print(fmt % (fit(info[0]), info[1], info[2], fit(info[3]), *pos, *vel), file=file)\n",
    "    else:\n",
    "      fmt = \"%5d%-5s%5s%5d\" + f\"%{w}.{p}f\" * 3\n",
    "      for info, pos in zip(self.info, self.pos):\n",
    "        print(fmt % (*info, *pos), file=file)\n",
    "    w = self.box_width\n",
    "    b = w - 5\n",
    "    fmt = f\"%{w}.{b}f\" * (9 if self.box_explicit_diag else 3)\n",
    "    print(fmt % self.box, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A function which modifies a Gro coordinates object `y`, changing the order of its atoms to match an interleaved Itp `x`, as per the provided `atom_id_map`.\n",
    "def rearrange_coordinates(y, atom_id_map):\n",
    "  try:\n",
    "    data = list(zip(y.info, y.pos, y.vel))\n",
    "  except TypeError:\n",
    "    data = list(zip(y.info, y.pos))\n",
    "  new_data = list()\n",
    "  for old_id, new_id in atom_id_map.items():\n",
    "    t = data[old_id - 1]\n",
    "    t = ((*t[0][:3], new_id), *t[1:])\n",
    "    new_data.append(t)\n",
    "  new_data_sep = list(zip(*new_data))\n",
    "  try:\n",
    "    y.info, y.pos, y.vel = new_data_sep\n",
    "  except ValueError:\n",
    "    y.info, y.pos = new_data_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74058ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown A function which combines multiple \"forcefield.itp\" / \"molecule.prm\" topology files, taking care with directive order.\n",
    "def combine_itp_files(filenames_in, filename_out):\n",
    "  all_parsed_files = [Itp(filename) for filename in filenames_in]\n",
    "  def index(blocks, key):\n",
    "    return next((i for i, t in enumerate(blocks) if t == key or hasattr(t, \"line\") and t.line.replace(\" \", \"\") == f\"[{key}]\"), None)\n",
    "  with open(filename_out, \"w\") as out:\n",
    "    for key in Itp.directive_order_hint:\n",
    "      for x in all_parsed_files:\n",
    "        i = index(x.blocks, key)\n",
    "        if i is not None:\n",
    "          if x.blocks[i] is not None:\n",
    "            print(x._str(x.blocks[i]), file=out)\n",
    "          for t in x.data[i]:\n",
    "            print(x._str(t), file=out)\n",
    "          if key == \"defaults\":\n",
    "            break\n",
    "    for x in all_parsed_files:\n",
    "      for block, data in zip(x.blocks, x.data):\n",
    "        if block is not None and \"\".join(c for c in block.line if c not in \"[ ]\") not in Itp.directive_order_hint:\n",
    "          print(x._str(block), file=out)\n",
    "          for t in data:\n",
    "            print(x._str(t), file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile superpose.py\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import numpy as np\n",
    "from Bio.PDB import Superimposer, PDBParser\n",
    "par = PDBParser()\n",
    "target = par.get_structure(\"target\", sys.argv[1])[0]\n",
    "query = par.get_structure(\"query\", sys.argv[2])[0]\n",
    "target_atoms = [res[\"CA\"] for ch in target for res in ch if \"CA\" in res]\n",
    "query_atoms = [res[\"CA\"] for ch in query for res in ch if \"CA\" in res]\n",
    "sup = Superimposer()\n",
    "sup.set_atoms(target_atoms, query_atoms)\n",
    "print(f\"RMSD: {sup.rms}\", file=sys.stderr)\n",
    "ro, tr = sup.rotran\n",
    "print(\"Transformation:\", file=sys.stderr)\n",
    "print(ro, file=sys.stderr)\n",
    "print(tr, file=sys.stderr)\n",
    "with open(\"rms.txt\", \"w\") as o:\n",
    "  print(sup.rms, file=o)\n",
    "np.save(\"ro.npy\", ro, allow_pickle=False)\n",
    "np.save(\"tr.npy\", tr, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01c572",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile insert_molecules_auto_topol\n",
    "#!/usr/bin/env bash\n",
    "topol=\"$1\"\n",
    "insert_mol=\"$2\"\n",
    "replace_mol=\"$3\"\n",
    "shift 3\n",
    "if [[ ! -s \"$topol\" || -z \"$insert_mol\" || -z \"$replace_mol\" ]]; then\n",
    "  exit 1\n",
    "fi\n",
    "gmx insert-molecules \"$@\" &> \"insert-molecules.log\"\n",
    "ret=$?\n",
    "if (( $ret != 0 )); then\n",
    "  cat \"insert-molecules.log\" >&2\n",
    "  exit $ret\n",
    "fi\n",
    "num_inserted=\"$(egrep -o \"Added [0-9]+ molecules\" \"insert-molecules.log\" | awk '{ print $2 }')\"\n",
    "if (( $num_inserted == 0 )); then\n",
    "  echo \"Error: could not insert molecule ${insert_mol}, no changes made to topology file ${topol}\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "num_replaced=\"$(egrep -o \"Replaced [0-9]+ residues\" \"insert-molecules.log\" | awk '{ print $2 }')\"\n",
    "awk \\\n",
    "  -v molins=\"$insert_mol\" \\\n",
    "  -v numins=$num_inserted \\\n",
    "  -v molrep=\"$replace_mol\" \\\n",
    "  -v numrep=$num_replaced \\\n",
    "  '\n",
    "  !x\n",
    "  x {\n",
    "    if ($1 == molins) {\n",
    "      print $1, $2 + numins\n",
    "      inserted=1\n",
    "    }\n",
    "    else if ($1 == molrep) {\n",
    "      print $1, $2 - numrep\n",
    "    }\n",
    "    else {\n",
    "      print $0\n",
    "    }\n",
    "  }\n",
    "  $0 ~ /\\[ *molecules *\\]/ {\n",
    "    x=1\n",
    "  }\n",
    "  END {\n",
    "    if (!inserted) {\n",
    "      print molins, numins\n",
    "    }\n",
    "  }\n",
    "  ' \\\n",
    "  \"${topol}\" \\\n",
    "  > \"${topol}.new\" \\\n",
    "&& mv \"${topol}.new\" \"${topol}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b04333",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile forcefield_POT_CLA.top\n",
    "[ atomtypes ]\n",
    "     CLA 17 35.4500 -1.000 A 4.04468018036e-01 6.276000e-01\n",
    "     POT 19 39.0983 1.000 A 3.14264522824e-01 3.640080e-01\n",
    "[ nonbond_params ]\n",
    "    CLA POT 1 3.63575766873e-01 4.77812800000e-01\n",
    "    POT OC 1 3.13952708273e-01 4.27604800000e-01\n",
    "[ pairtypes ]\n",
    "    CP1 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CP1 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "    CP2 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CP2 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "    CP3 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CP3 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "    CT1 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CT1 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "    CT2 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CT2 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "   CT2A CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "   CT2A POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "    CT3 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "    CT3 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "   CTL1 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "   CTL1 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "   CTL2 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "   CTL2 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "   CTL3 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "   CTL3 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "   CTL5 CLA 1 3.71504765465e-01 1.62045623205e-01\n",
    "   CTL5 POT 1 3.26403017859e-01 1.23410269913e-01\n",
    "      N CLA 1 3.67050271874e-01 1.62045623205e-02\n",
    "      N POT 1 3.21948524268e-01 1.23410269913e-02\n",
    "    NH1 CLA 1 3.40323310330e-01 7.24690057887e-01\n",
    "    NH1 POT 1 2.95221562724e-01 5.51907505294e-01\n",
    "      O CLA 1 3.26959829558e-01 5.61342505072e-01\n",
    "      O POT 1 2.81858081952e-01 4.27505715330e-01\n",
    "    OBL CLA 1 3.26959829558e-01 5.61342505072e-01\n",
    "    OBL POT 1 2.81858081952e-01 4.27505715330e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1eb034",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile POT.ipt\n",
    "[ moleculetype ]\n",
    "POT 1\n",
    "[ atoms ]\n",
    "     1 POT 1 POT POT 1 1.000000 39.0983 ; qtot 1.000\n",
    "\n",
    "%%writefile CLA.ipt\n",
    "[ moleculetype ]\n",
    "CLA 1\n",
    "[ atoms ]\n",
    "     1 CLA 38 CLA CLA 1 -1.000000 35.4500 ; qtot -1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cff5d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "cp protein/gromacs/step*_input.gro \"conf.gro\"\n",
    "cp -r protein/gromacs/{index.ndx,topol.top,toppar} .\n",
    "if [[ ! -s \"conf.gro\" || ! -s \"index.ndx\" || ! -s \"topol.top\" ]]; then\n",
    "  echo \"Error: could not extract protein system\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "function gro_residues {\n",
    "  for f in \"$@\"; do tail -n+3 \"${f}\" | head -n-1; done | cut -c6-9 | sort | uniq -c | sort -r | awk '{ print $2 }'\n",
    "}\n",
    "if fgrep -q \"[ MEMB ]\" \"index.ndx\"; then\n",
    "  gmx editconf -f \"conf.gro\" -n \"index.ndx\" -o \"MEMB.gro\" <<< \"MEMB\"\n",
    "  gro_residues \"MEMB.gro\" > \"MEMB.txt\"\n",
    "  rm \"MEMB.gro\"\n",
    "fi\n",
    "gmx editconf -f \"conf.gro\" -n \"index.ndx\" -o \"SOLV.gro\" <<< \"SOLV\"\n",
    "gro_residues \"SOLV.gro\" > \"SOLV.txt\"\n",
    "rm \"SOLV.gro\"\n",
    "rm \"index.ndx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638504f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "eval \"$(\"$START/miniconda3/bin/conda\" shell.bash hook)\"\n",
    ":> \"add.txt\"\n",
    ":> \"restrain.txt\"\n",
    "for d in ligand_*; do\n",
    "  IFS=_ read type i <<< $d\n",
    "  if [[ \"${i}\" == \"*\" ]]; then continue; fi\n",
    "  if [[ -s \"${type}_${i}/lig/lig.rtf\" && -s \"${type}_${i}/lig/lig.prm\" ]]; then\n",
    "    name_=\"LIG \"\n",
    "    n=$(find -maxdepth 1 -name \"${type}_*\" -type d | wc -l)\n",
    "    if (( $n > 1 )); then name_=\"${name_::$((4 - ${#n}))}${n}\"; fi\n",
    "    name=\"$(echo $name_)\"\n",
    "    namell=\"${name,,}\"\n",
    "    mkdir -p \"${name}\"\n",
    "    { echo \"* For use with CGenFF version 4.6\"; cat \"${type}_${i}/lig/lig.rtf\"; echo \"read para\"; cat \"${type}_${i}/lig/lig.prm\"; } | sed \"s/ lig / ${name_}/g\" > \"${name}/${name}.str\"\n",
    "    conda activate \"biopython\"\n",
    "    obabel \"${type}_${i}/ligandrm.pdb\" -O \"${name}/${name}.mol2\" --title \"${name}\" --partialcharge none\n",
    "    pushd \"${name}\"\n",
    "    conda activate \"charmm2gmx\"\n",
    "    cgenff_charmm2gmx.py \"${name}\" \"${name}.mol2\" \"${name}.str\" \"${START}/charmm36.ff\"\n",
    "    popd\n",
    "    gmx editconf -f \"${name}/${namell}_ini.pdb\" -o \"${name}.gro\"\n",
    "    cp \"${name}/${namell}.prm\" \"toppar/${name}.prm\"\n",
    "    cp \"${name}/${namell}.itp\" \"toppar/${name}.itp\"\n",
    "    if [[ ! -d \"toppar/charmm36.ff\" ]]; then cp -r \"${START}/charmm36.ff\" \"toppar/\"; fi\n",
    "  elif [[ -s \"${type}_${i}/gromacs/topol.top\" ]]; then\n",
    "    name=\"$(tail -n1 \"${type}_${i}/gromacs/topol.top\" | awk '{ print $1 }')\"\n",
    "    gmx editconf -f \"${type}_${i}/ligandrm.pdb\" -o \"${name}.gro\"\n",
    "    cp \"${type}_${i}/gromacs/charmm36.itp\" \"toppar/forcefield_${name}.itp\"\n",
    "    cp \"${type}_${i}/gromacs/${name}.itp\" \"toppar/\"\n",
    "  else\n",
    "    echo \"Error: incompatible molecule: ${type}_${i}\" >&2\n",
    "    exit 1\n",
    "  fi\n",
    "  echo \"${name}\" >> \"add.txt\"\n",
    "  echo \"${name}\" >> \"restrain.txt\"\n",
    "done\n",
    "\n",
    "with open(\"add.txt\") as f:\n",
    "  for l in f:\n",
    "    l = l.strip()\n",
    "    x = Itp(f\"toppar/{l}.itp\")\n",
    "    atom_id_map = interleave_H_in_topology(x)\n",
    "    y = Gro(f\"{l}.gro\")\n",
    "    rearrange_coordinates(y, atom_id_map)\n",
    "    with open(f\"toppar/{l}.itp\", \"w\") as o: x.print(file=o)\n",
    "    with open(f\"{l}.gro\", \"w\") as o: y.print(file=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a315e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "while read -r name; do\n",
    "  if fgrep -q \"POSRES_FC_LIG\" \"toppar/${name}.itp\"; then continue; fi\n",
    "  gmx genrestr -f \"${name}.gro\" -fc 9999 <<< \"0\"\n",
    "  { echo \"\"; echo \"#ifdef POSRES\"; tail -n+3 \"posre.itp\" | sed \"s/9999/POSRES_FC_LIG/g\"; echo \"#endif\"; echo \"\"; } >> \"toppar/${name}.itp\"\n",
    "  rm \"posre.itp\"\n",
    "done < \"restrain.txt\"\n",
    "\n",
    "if not os.path.isdir(\"toppar/charmm36.ff\"):\n",
    "  if not os.path.isfile(\"toppar/forcefield_POT_CLA.itp\"):\n",
    "    !cp \"forcefield_POT_CLA.itp\" \"toppar/forcefield_POT_CLA.itp\"\n",
    "    !echo \"POT_CLA\" >> \"add.txt\"\n",
    "  if not os.path.isfile(\"toppar/POT.itp\"):\n",
    "    !cp \"POT.itp\" \"toppar/POT.itp\"\n",
    "    !echo \"POT\" >> \"add.txt\"\n",
    "  if not os.path.isfile(\"toppar/CLA.itp\"):\n",
    "    !cp \"CLA.itp\" \"toppar/CLA.itp\"\n",
    "    !echo \"CLA\" >> \"add.txt\"\n",
    "\n",
    "forcefield_itps = [\"toppar/forcefield.itp\"]\n",
    "try:\n",
    "  with open(\"add.txt\") as f:\n",
    "    forcefield_itps += [f\"toppar/forcefield_{l.strip()}.itp\" for l in f if os.path.isfile(f\"toppar/forcefield_{l.strip()}.itp\")]\n",
    "except FileNotFoundError: pass\n",
    "\n",
    "if os.path.isdir(\"toppar/charmm36.ff\"):\n",
    "  with open(\"topol.top\") as f, open(\"topol.top.new\", \"w\") as o:\n",
    "    for l in f:\n",
    "      if l.rstrip() == '#include \"toppar/forcefield.itp\"':\n",
    "        print('#include \"toppar/charmm36.ff/forcefield.itp\"', file=o)\n",
    "      else: o.write(l)\n",
    "  os.rename(\"topol.top.new\", \"topol.top\")\n",
    "  for itp in forcefield_itps: os.remove(itp)\n",
    "elif len(forcefield_itps) > 1:\n",
    "  combine_itp_files(forcefield_itps, \"toppar/forcefield.itp\")\n",
    "  for itp in forcefield_itps[1:]: os.remove(itp)\n",
    "\n",
    "prm_itp_files = list()\n",
    "try:\n",
    "  with open(\"add.txt\") as f:\n",
    "    prm_itp_files = [f\"toppar/{l.strip()}.{ext}\" for l in f for ext in (\"itp\", \"prm\") if os.path.isfile(f\"toppar/{l.strip()}.{ext}\")]\n",
    "except FileNotFoundError: pass\n",
    "if prm_itp_files:\n",
    "  prm_files = [f for f in prm_itp_files if f.endswith(\".prm\")]\n",
    "  itp_files = [f for f in prm_itp_files if f.endswith(\".itp\")]\n",
    "  with open(\"topol.top\") as f, open(\"topol.top.new\", \"w\") as o:\n",
    "    l_prev = \"\"\n",
    "    for l in f:\n",
    "      if \"forcefield.itp\" in l_prev and \"forcefield.itp\" not in l:\n",
    "        for prm_file in prm_files: print(f'#include \"{prm_file}\"', file=o)\n",
    "      if l_prev.startswith(\"#include\") and not l.startswith(\"#include\"):\n",
    "        for itp_file in itp_files: print(f'#include \"{itp_file}\"', file=o)\n",
    "      o.write(l)\n",
    "      l_prev = l\n",
    "  os.rename(\"topol.top.new\", \"topol.top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07390c55",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$remove_cmaps_bash\"\n",
    "remove_cmaps_bash=\"$1\"\n",
    "if $remove_cmaps_bash; then\n",
    "  pushd \"toppar\"\n",
    "  while read -r f; do\n",
    "    in_cmap=false\n",
    "    while IFS=\"\" read -r l; do\n",
    "      if $in_cmap; then\n",
    "        if [[ \"${l}\" =~ ^[[:space:]]*\\[ ]]; then in_cmap=false; fi\n",
    "        if ! $in_cmap || [[ \"${l}\" =~ ^[[:space:]]*$ || \"${l}\" =~ ^[[:space:]]*'#' || \"${l}\" =~ ^[[:space:]]*';' ]]; then printf \"%s\\n\" \"${l}\"; fi\n",
    "      elif [[ \"${l}\" =~ ^[[:space:]]*\\[[[:space:]]*[cC][mM][aA][pP][[:space:]]*\\][[:space:]]*$ ]]; then\n",
    "        in_cmap=true\n",
    "      else\n",
    "        printf \"%s\\n\" \"${l}\"\n",
    "      fi\n",
    "    done < \"${f}\" > \"${f}.tmp\"\n",
    "    mv \"${f}.tmp\" \"${f}\"\n",
    "  done < <(egrep -l -i '^\\s*\\[\\s*cmap\\s*\\]\\s*$' -r .)\n",
    "  popd\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fec226",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "eval \"$(\"$START/miniconda3/bin/conda\" shell.bash hook)\"\n",
    "conda activate \"biopython\"\n",
    "python3 superpose.py protein/gromacs/step*_input.pdb \"protein/step1_pdbreader.pdb\"\n",
    "rms=\"$(cat \"rms.txt\")\"\n",
    "if perl -e \"exit !(${rms} > 1.0)\"; then\n",
    "  echo \"Error: failed to match CHARMM-GUI protein input coordinates to output coordinates: RMSD = ${rms}\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "import numpy as np\n",
    "ro = np.load(\"ro.npy\")\n",
    "tr = np.load(\"tr.npy\")\n",
    "try:\n",
    "  with open(\"restrain.txt\") as f:\n",
    "    for l in f:\n",
    "      l = l.strip()\n",
    "      x = Gro(f\"{l}.gro\")\n",
    "      pos = np.array(x.pos)\n",
    "      new_pos = (pos @ ro) + (tr / 10.)\n",
    "      x.pos = [tuple(row) for row in new_pos]\n",
    "      if x.vel is not None:\n",
    "        vel = np.array(x.vel)\n",
    "        new_vel = vel @ ro\n",
    "        x.vel = [tuple(row) for row in new_vel]\n",
    "      x.box_explicit_diag = False\n",
    "      x.box = (0., 0., 0.)\n",
    "      with open(f\"{l}.gro\", \"w\") as o: x.print(file=o)\n",
    "except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d85aa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "n=$(ls \"#topol.top.\"*\"#\" 2> /dev/null | wc -l)\n",
    "cp \"topol.top\" \"#topol.top.${n}#\"\n",
    "while read -r name; do\n",
    "  echo \"0 0 0\" > \"positions.dat\"\n",
    "  water=\"$(egrep \"(TIP|OPC)\" \"SOLV.txt\" | head -n1)\"\n",
    "  dr=0.0289\n",
    "  bash insert_molecules_auto_topol \"topol.top\" \"${name}\" \"${water}\" \\\n",
    "    -f \"conf.gro\" -ci \"${name}.gro\" -ip \"positions.dat\" -rot none -dr $dr $dr $dr -replace \"resname ${water}\" -try 99 -scale 0.235 -o \"out.gro\" \\\n",
    "  && mv \"out.gro\" \"conf.gro\"\n",
    "done < \"restrain.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b4735",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "step0=$(ls -v \"protein/gromacs/\" | fgrep \"minimization.mdp\")\n",
    "cp \"protein/gromacs/$step0\" \"pre_0.mdp\"\n",
    "sed -i\"\" '/^define/d' \"pre_0.mdp\"\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "export GMX_MAXCONSTRWARN=-1\n",
    "gmx grompp -f \"pre_0.mdp\" -o \"pre_0.tpr\" -c \"conf.gro\" -p \"topol.top\" -maxwarn 999\n",
    "gmx genion -s \"pre_0.tpr\" -o \"conf.gro\" -p \"topol.top\" -pname \"POT\" -nname \"CLA\" -neutral < <(egrep \"(TIP|OPC)\" \"SOLV.txt\" | head -n1)\n",
    "if ! grep -q \"POT\" \"SOLV.txt\" && grep -q \"^POT \" \"topol.top\"; then echo \"POT\" >> \"SOLV.txt\"; fi\n",
    "if ! grep -q \"CLA\" \"SOLV.txt\" && grep -q \"^CLA \" \"topol.top\"; then echo \"CLA\" >> \"SOLV.txt\"; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d9039",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "gmx make_ndx -f \"conf.gro\" < /dev/null 2> /dev/null | fgrep \" : \" > \"index_autodetect.txt\"\n",
    "nr=$(cat \"index_autodetect.txt\" | wc -l)\n",
    "\n",
    "SOLV_defn=\"$(cat \"SOLV.txt\" | tr \"\\n\" \"@\" | sed 's/^/\"/; s/@$/\"/; s/@/\" | \"/g')\"\n",
    "{\n",
    "  echo \"${SOLV_defn}\"\n",
    "  echo \"name ${nr} SOLV\"\n",
    "} > \"index_commands.txt\"\n",
    "nr=$(($nr + 1))\n",
    "if [[ ! -s \"MEMB.txt\" ]]; then\n",
    "  { echo '! \"SOLV\"'; echo \"name ${nr} SOLU\"; } >> \"index_commands.txt\"\n",
    "else\n",
    "  MEMB_defn=\"$(cat \"MEMB.txt\" | tr \"\\n\" \"@\" | sed 's/^/\"/; s/@$/\"/; s/@/\" | \"/g')\"\n",
    "  { echo \"${MEMB_defn}\"; echo \"name ${nr} MEMB\"; } >> \"index_commands.txt\"\n",
    "  nr=$(($nr + 1))\n",
    "  { echo '! \"SOLV\" & ! \"MEMB\"'; echo \"name ${nr} SOLU\"; } >> \"index_commands.txt\"\n",
    "  nr=$(($nr + 1))\n",
    "  { echo '\"SOLU\" | \"MEMB\"'; echo \"name ${nr} SOLU_MEMB\"; } >> \"index_commands.txt\"\n",
    "fi\n",
    "echo \"q\" >> \"index_commands.txt\"\n",
    "gmx make_ndx -f \"conf.gro\" -o \"index.ndx\" < \"index_commands.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b00d5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "step0=$(ls -v \"protein/gromacs/\" | fgrep \"minimization.mdp\")\n",
    "cp \"protein/gromacs/$step0\" \"pre_0.mdp\"\n",
    "i=1\n",
    "while read -r step; do\n",
    "  cp \"protein/gromacs/$step\" \"pre_$i.mdp\"\n",
    "  i=$(($i + 1))\n",
    "done < <(ls -v \"protein/gromacs/\" | fgrep \"equilibration.mdp\")\n",
    "\n",
    "if [[ -s \"restrain.txt\" ]]; then\n",
    "  for f in pre_*.mdp; do\n",
    "    bb=\"$(head -n1 \"$f\" | egrep -o \"\\-DPOSRES_FC_BB=[^ ]+\")\"\n",
    "    sed -i\"\" \"s/$bb/$(echo \"$bb\" | sed 's/_BB/_LIG/') $bb/\" \"$f\"\n",
    "  done\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf6323",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$do_double_eq_bash\"\n",
    "do_double_eq_bash=\"$1\"\n",
    "if $do_double_eq_bash; then\n",
    "  for f in pre_*.mdp; do\n",
    "    pre_nsteps=\"$(sed -n -E 's/^(\\s*nsteps\\s*=\\s*)([0-9]+)(.*?)$/\\2/p' \"${f}\" | head -n1)\"\n",
    "    double_nsteps=\"$(perl -l <<< \"print(2.0 * ${pre_nsteps})\")\"\n",
    "    sed -i\"\" -E 's/^(\\s*nsteps\\s*=\\s*)([0-9]+)(.*?)$/\\1'\"${double_nsteps}\"'\\3/' \"${f}\"\n",
    "  done\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"production.mdp\"\n",
    "integrator = md\n",
    "dt = 0.002\n",
    "nsteps = 500000\n",
    "comm-mode = Linear\n",
    "nstxout = 10000\n",
    "nstvout = 10000\n",
    "nstenergy = 0\n",
    "cutoff-scheme = Verlet\n",
    "nstlist = 100\n",
    "coulombtype = PME\n",
    "rcoulomb = 1.2\n",
    "vdwtype = Cut-off\n",
    "vdw-modifier = Force-switch\n",
    "rvdw-switch = 1.0\n",
    "rvdw = 1.2\n",
    "tcoupl = V-Rescale\n",
    "tc-grps = %tc-grps%\n",
    "tau-t = %tau-t%\n",
    "ref-t = %ref-t%\n",
    "pcoupl = C-Rescale\n",
    "pcoupltype = %pcoupltype%\n",
    "tau-p = 5.0\n",
    "compressibility = %compressibility%\n",
    "ref-p = %ref-p%\n",
    "constraints = h-bonds\n",
    "constraint-algorithm = LINCS\n",
    "continuation = yes\n",
    "\n",
    "ref_t=\"$(awk '($1 == \"ref_t\" || $1 == \"ref-t\") { print $3; exit }' \"pre_1.mdp\")\"\n",
    "sed -i\"\" \"/^#@markdown/d\" \"production.mdp\"\n",
    "if [[ -s \"MEMB.txt\" ]]; then\n",
    "  sed -i\"\" \"\n",
    "    s/%tc-grps%/SOLU SOLV MEMB /g;\n",
    "    s/%tau-t% /1.0 1.0 1.0 /g;\n",
    "    s/%ref-t% /${ref_t} ${ref_t} ${ref_t}/g;\n",
    "    s/%pcoupltype% /semiisotropic /g;\n",
    "    s/%compressibility%/4.5e-5 4.5e-5/g;\n",
    "    s/%ref-p% /1.0 1.0 /g;\n",
    "  \" \"production.mdp\"\n",
    "else\n",
    "  sed -i\"\" \"\n",
    "    s/%tc-grps%/SOLU SOLV /g;\n",
    "    s/%tau-t% /1.0 1.0 /g;\n",
    "    s/%ref-t% /${ref_t} ${ref_t}/g;\n",
    "    s/%pcoupltype% /isotropic/g;\n",
    "    s/%compressibility%/4.5e-5 /g;\n",
    "    s/%ref-p% /1.0 /g;\n",
    "  \" \"production.mdp\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"run.bash\"\n",
    "output_folder=\"$1\"\n",
    "cp conf.gro restraint.gro\n",
    "if ! mkdir -p \"${output_folder}\"; then\n",
    "  echo \"Error: invalid folder: ${output_folder}\" >&2\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "source \"/usr/local/gromacs/bin/GMXRC.bash\"\n",
    "export GMX_MAXCONSTRWARN=-1\n",
    "echo \"Notice: saving output to folder: ${output_folder}\"\n",
    "sleep 1\n",
    "i=0\n",
    "while [[ -s \"pre_${i}.mdp\" ]]; do\n",
    "  if [[ -s \"${output_folder}/pre_${i}.gro\" ]]; then\n",
    "    cp \"${output_folder}/pre_${i}.gro\" .\n",
    "  else\n",
    "    if (( $i == 0 )); then\n",
    "      gmx grompp -f \"pre_${i}.mdp\" -o \"pre_${i}.tpr\" -c \"conf.gro\" -r \"restraint.gro\" -p \"topol.top\" -n \"index.ndx\" -maxwarn 999\n",
    "      gmx mdrun -deffnm \"pre_${i}\" || exit $?\n",
    "    else\n",
    "      prev=$(($i - 1))\n",
    "      gmx grompp -f \"pre_${i}.mdp\" -o \"pre_${i}.tpr\" -c \"pre_${prev}.gro\" -r \"restraint.gro\" -p \"topol.top\" -n \"index.ndx\" -maxwarn 999\n",
    "      gmx mdrun -v -stepout 1000 -deffnm \"pre_${i}\" -bonded gpu || exit $?\n",
    "    fi\n",
    "    cp \"pre_${i}.gro\" \"pre_${i}.log\" \"${output_folder}/\"\n",
    "  fi\n",
    "  i=$(($i + 1))\n",
    "done\n",
    "\n",
    "i=$(($i - 1))\n",
    "cp \"production.mdp\" \"${output_folder}/grompp.mdp\"\n",
    "cp \"pre_${i}.gro\" \"${output_folder}/conf.gro\"\n",
    "cp -r \"index.ndx\" \"restraint.gro\" \"topol.top\" \"toppar\" \"${output_folder}/\"\n",
    "gmx trjconv -s \"pre_${i}.tpr\" -f \"pre_${i}.gro\" -o \"conf.pdb\" <<< \"0\"\n",
    "cp \"conf.pdb\" \"${output_folder}/\"\n",
    "exit 0\n",
    "\n",
    "!bash \"run.bash\" \"$output_folder\"\n",
    "!sleep 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0838c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disconnect = True #@param {type: \"boolean\"}\n",
    "if disconnect and output_folder.startswith(\"/content/drive/MyDrive/\"):\n",
    "  from google.colab import drive, runtime\n",
    "  drive.flush_and_unmount()\n",
    "  runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
